{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He added that the scheme aims to attract regional and Malaysian families to manage their family wealth from Malaysia. Supported by good infrastructure, a competitive talent pool, robust common law practices and effective governance, opportunities abound for family offices,” said Mr Amir Hamzah. This scheme is aimed at being operational by the first quarter of 2025, he added. During a press conference after his speech, Mr Amir Hamzah explained that these companies will be subject to zero per cent tax when they file revenue of their transactions for 10 years.He added that the incentives can then be extended if the family offices scale up investments and assets of their operations in Malaysia. Mr Amir Hamzah added that a key criteria is that these family offices must have minimum assets of RM70 million (US$16.73 million), and a portion of these must be invested in Malaysia’s economy. \n"
     ]
    }
   ],
   "source": [
    "# create a text with 1024 characters\n",
    "\n",
    "text= [\"He added that the scheme aims to attract regional and Malaysian families to manage their family wealth from Malaysia. Supported by good infrastructure, a competitive talent pool, robust common law practices and effective governance, opportunities abound for family offices,” said Mr Amir Hamzah. This scheme is aimed at being operational by the first quarter of 2025, he added. During a press conference after his speech, Mr Amir Hamzah explained that these companies will be subject to zero per cent tax when they file revenue of their transactions for 10 years.He added that the incentives can then be extended if the family offices scale up investments and assets of their operations in Malaysia. Mr Amir Hamzah added that a key criteria is that these family offices must have minimum assets of RM70 million (US$16.73 million), and a portion of these must be invested in Malaysia’s economy. \"]\n",
    "for i in text:\n",
    "    print(i)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_core-0.3.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.125-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "     ---------------------------------------- 0.0/149.4 kB ? eta -:--:--\n",
      "     -------- ------------------------------ 30.7/149.4 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------- --------- 112.6/149.4 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 149.4/149.4 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.0->langchain)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.9.0)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.7-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 51.7/51.7 kB ? eta 0:00:00\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: sniffio in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (2.1)\n",
      "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.2/1.0 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.4/1.0 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.5/1.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 0.7/1.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 0.9/1.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.2-py3-none-any.whl (399 kB)\n",
      "   ---------------------------------------- 0.0/399.7 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 225.3/399.7 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 399.7/399.7 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.125-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.2 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 204.8/290.2 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 290.2/290.2 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.9 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 266.2/434.9 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 434.9/434.9 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 8.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/1.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/1.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/1.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.7/1.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 5.3 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.7-cp311-none-win_amd64.whl (137 kB)\n",
      "   ---------------------------------------- 0.0/137.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 137.3/137.3 kB 7.9 MB/s eta 0:00:00\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: pydantic-core, packaging, orjson, jsonpatch, h11, annotated-types, pydantic, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.12\n",
      "    Uninstalling pydantic-1.10.12:\n",
      "      Successfully uninstalled pydantic-1.10.12\n",
      "Successfully installed annotated-types-0.7.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 langchain-0.3.0 langchain-core-0.3.2 langchain-text-splitters-0.3.0 langsmith-0.1.125 orjson-3.10.7 packaging-24.1 pydantic-2.9.2 pydantic-core-2.23.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.9.2 which is incompatible.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He added that the scheme aims to attract regional and Malaysian families to manage their family wealth from Malaysia. Supported by good infrastructure, a competitive talent pool, robust common law practices and effective governance, opportunities abound for family offices,” said Mr Amir Hamzah. This scheme is aimed at being operational by the first quarter of 2025, he added. During a press conference after his speech, Mr Amir Hamzah explained that these companies will be subject to zero per cent tax when they file revenue of their transactions for 10 years.He added that the incentives can then be extended if the family offices scale up investments and assets of their operations in Malaysia. Mr Amir Hamzah added that a key criteria is that these family offices must have minimum assets of RM70 million (US$16.73 million), and a portion of these must be invested in Malaysia’s economy.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['He added that the scheme',\n",
       " 'aims to attract regional',\n",
       " 'and Malaysian families',\n",
       " 'to manage their family',\n",
       " 'wealth from Malaysia.',\n",
       " 'Supported by good',\n",
       " 'good infrastructure, a',\n",
       " 'a competitive talent',\n",
       " 'pool, robust common law',\n",
       " 'law practices and',\n",
       " 'and effective',\n",
       " 'governance,',\n",
       " 'opportunities abound for',\n",
       " 'for family offices,”',\n",
       " 'said Mr Amir Hamzah.',\n",
       " 'This scheme is aimed at',\n",
       " 'at being operational by',\n",
       " 'by the first quarter of',\n",
       " 'of 2025, he added.',\n",
       " 'During a press',\n",
       " 'conference after his',\n",
       " 'his speech, Mr Amir',\n",
       " 'Amir Hamzah explained',\n",
       " 'that these companies',\n",
       " 'will be subject to zero',\n",
       " 'zero per cent tax when',\n",
       " 'when they file revenue',\n",
       " 'of their transactions',\n",
       " 'for 10 years.He added',\n",
       " 'that the incentives can',\n",
       " 'can then be extended if',\n",
       " 'if the family offices',\n",
       " 'scale up investments and',\n",
       " 'and assets of their',\n",
       " 'operations in Malaysia.',\n",
       " 'Mr Amir Hamzah added',\n",
       " 'that a key criteria is',\n",
       " 'is that these family',\n",
       " 'offices must have',\n",
       " 'have minimum assets of',\n",
       " 'of RM70 million',\n",
       " '(US$16.73 million), and',\n",
       " 'and a portion of these',\n",
       " 'must be invested in',\n",
       " 'in Malaysia’s economy.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Example for character-level splitting\n",
    "text_splitter = CharacterTextSplitter(chunk_size=25, chunk_overlap=5)\n",
    "chunks = text_splitter.split_text(text[0])\n",
    "print(chunks)\n",
    "\n",
    "# Example for word-based splitting (Recursive splitting)\n",
    "word_splitter = RecursiveCharacterTextSplitter(chunk_size=25, chunk_overlap=5)\n",
    "word_chunks = word_splitter.split_text(text[0])\n",
    "print(word_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He added that the scheme aims to attract regional and Malaysian families to manage their family wealth from Malaysia. Supported by good infrastructure, a competitive talent pool, robust common law practices and effective governance, opportunities abound for family offices,” said Mr Amir Hamzah. This scheme is aimed at being operational by the first quarter of 2025, he added. During a press conference after his speech, Mr Amir Hamzah explained that these companies will be subject to zero per cent tax when they file revenue of their transactions for 10 years.He added that the incentives can then be extended if the family offices scale up investments and assets of their operations in Malaysia. Mr Amir Hamzah added that a key criteria is that these family offices must have minimum assets of RM70 million (US$16.73 million), and a portion of these must be invested in Malaysia’s economy.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/DataScience_For_mySelf/Projects_myself/RagMLOPS/TriModalRAG_System\n",
      "d:\\DataScience_For_mySelf\\Projects_myself\\RagMLOPS\\TriModalRAG_System\\data\\image\n",
      "d:\\DataScience_For_mySelf\\Projects_myself\\RagMLOPS\\TriModalRAG_System\\data\\image\\weather_images_0.png\n",
      "weather_images_0.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "ROOT_PROJECT_DIR = os.getcwd().split(\"\\\\\")[:-1]\n",
    "ROOT_PROJECT_DIR = \"/\".join(ROOT_PROJECT_DIR)\n",
    "print(ROOT_PROJECT_DIR)\n",
    "text_dir = Path(ROOT_PROJECT_DIR + \"/data/image\")\n",
    "print(text_dir)\n",
    "# print(text_dir.glob(\"*.png\"))\n",
    "for text_p in text_dir.glob(\"*.png\"):\n",
    "    print(text_p)\n",
    "    text_url = os.path.basename(text_p)\n",
    "    print(text_url)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\DataScience_For_mySelf\\Projects_myself\\RagMLOPS\\TriModalRAG_System\\data\\image\n",
      "d:\\DataScience_For_mySelf\\Projects_myself\\RagMLOPS\\TriModalRAG_System\\data\\image\\src\\artifacts\\data\\embeddings\n"
     ]
    }
   ],
   "source": [
    "text_dir = Path(ROOT_PROJECT_DIR + \"/data/image\")\n",
    "print(text_dir)\n",
    "text_dir = text_dir /  (\"src/\"  \"artifacts/\" + \"data/\" + \"embeddings/\")\n",
    "print(text_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text_url': 'D:\\\\DataScience_For_mySelf\\\\Projects_myself\\\\RagMLOPS…',\n",
       "  'type': 'weather',\n",
       "  'title': '0_1406_3726v1.pdf'},\n",
       " {'text_url': 'D:\\\\DataScience_For_mySelf\\\\Projects_myself\\\\RagMLOPS…',\n",
       "  'type': 'weather',\n",
       "  'title': '1_1911_09001v1.pdf'},\n",
       " {'text_url': 'D:\\\\DataScience_For_mySelf\\\\Projects_myself\\\\RagMLOPS…',\n",
       "  'type': 'weather',\n",
       "  'title': '0_1406_3726v1.pdf'},\n",
       " {'text_url': 'D:\\\\DataScience_For_mySelf\\\\Projects_myself\\\\RagMLOPS…',\n",
       "  'type': 'weather',\n",
       "  'title': '1_1911_09001v1.pdf'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_text_urls = [\n",
    "    \"D:\\DataScience_For_mySelf\\Projects_myself\\RagMLOPS…\",\n",
    "    \"D:\\DataScience_For_mySelf\\Projects_myself\\RagMLOPS…\",\n",
    "    \"D:\\DataScience_For_mySelf\\Projects_myself\\RagMLOPS…\",\n",
    "    \"D:\\DataScience_For_mySelf\\Projects_myself\\RagMLOPS…\",\n",
    "]\n",
    "_types = [\n",
    "    \"weather\",\n",
    "    \"weather\",\n",
    "    \"weather\",\n",
    "    \"weather\",\n",
    "]\n",
    "titles = [\n",
    "    \"0_1406_3726v1.pdf\",\n",
    "    \"1_1911_09001v1.pdf\",\n",
    "    \"0_1406_3726v1.pdf\",\n",
    "    \"1_1911_09001v1.pdf\"\n",
    "]\n",
    "import pandas as pd\n",
    "\n",
    "pyloads = pd.DataFrame({\"text_url\": _text_urls,\n",
    "                                        \"type\": _types,\n",
    "                                        \"title\": titles})\n",
    "\n",
    "\n",
    "pyload_dicts = pyloads.to_dict(orient=\"records\")\n",
    "pyload_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_url': 'D:\\\\DataScience_For_mySelf\\\\Projects_myself\\\\RagMLOPS…',\n",
       " 'type': 'weather',\n",
       " 'title': '0_1406_3726v1.pdf'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyload_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pyload_dicts\u001b[38;5;241m.\u001b[39mitems())):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "for x in range(len(pyload_dicts.items())):\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\downloads\\program files\\anaconda\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "   ---------------------------------------- 0.0/436.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/436.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 112.6/436.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 256.0/436.4 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 436.4/436.4 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "   ---------------------------------------- 0.0/286.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 286.0/286.0 kB 17.2 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 32.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 15.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 17.7 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.25.1 safetensors-0.4.5 tokenizers-0.19.1 transformers-4.44.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 2023, 2003, 1037, 3231, 6251, 1012,  102]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'this', 'is', 'a', 'test', 'sentence', '.', '[SEP]']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "# Example input text\n",
    "text = \"This is a test sentence.\"\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Get the token IDs\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "print(input_ids)\n",
    "\n",
    "# Get embeddings from the BERT model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the last hidden state (embeddings)\n",
    "embeddings = outputs.last_hidden_state  # shape: [batch_size, sequence_length, hidden_size]\n",
    "\n",
    "# Convert input IDs back to tokens (for verification)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "# tokens_tesst = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "# print(tokens_tesst)\n",
    "\n",
    "# Print tokens and their corresponding embeddings\n",
    "tokens_list = [token for token, embedding in zip(tokens, embeddings[0])]\n",
    "tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "x = [[[1, 2, 3]],\n",
    "     [[4, 5, 6]],\n",
    "     [[1, 2, 3]],\n",
    "     [[4, 5, 6]],\n",
    "     ] # 2 x 1 x 3\n",
    "\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "b = \"ung\"\n",
    "c = True\n",
    "x = (a, b, c)\n",
    "print(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3]],\n",
       "\n",
       "        [[4, 5, 6]],\n",
       "\n",
       "        [[1, 2, 3]],\n",
       "\n",
       "        [[4, 5, 6]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor(x)\n",
    "x1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m [[[ \u001b[38;5;241m4.2606476e-03\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.2611354e-02\u001b[39m,  \u001b[38;5;241m1.5845066e-01\u001b[39m,\n\u001b[0;32m      2\u001b[0m          \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7.3490776e-02\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6.2923972e-03\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.2687368e-01\u001b[39m],\n\u001b[0;32m      3\u001b[0m         [ \u001b[38;5;241m7.1950510e-02\u001b[39m,  \u001b[38;5;241m1.1587572e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9.6582770e-02\u001b[39m,\n\u001b[0;32m      4\u001b[0m          \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.8304415e-01\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.2026648e-02\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.3342978e-02\u001b[39m]]], \n\u001b[0;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m [[[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.09848069\u001b[39m,  \u001b[38;5;241m0.06043535\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.04723791\u001b[39m,  \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1566387\u001b[39m ,\n\u001b[0;32m      6\u001b[0m           \u001b[38;5;241m0.01780085\u001b[39m,  \u001b[38;5;241m0.00295972\u001b[39m],\n\u001b[0;32m      7\u001b[0m         [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.094222\u001b[39m  ,  \u001b[38;5;241m0.05571611\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.04469165\u001b[39m,  \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.13713397\u001b[39m,\n\u001b[0;32m      8\u001b[0m           \u001b[38;5;241m0.02163608\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.00989413\u001b[39m]]]\n\u001b[1;32m---> 10\u001b[0m z \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mconcatenate(x, y)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m z:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "[array([[[ 4.2606476e-03, -2.2611354e-02,  1.5845066e-01,\n",
    "         -7.3490776e-02, -6.2923972e-03, -2.2687368e-01],\n",
    "        [ 7.1950510e-02,  1.1587572e-04, -9.6582770e-02,\n",
    "         -1.8304415e-01, -5.2026648e-02, -4.3342978e-02]]]),array( [[[-0.09848069,  0.06043535, -0.04723791,  -0.1566387 ,\n",
    "          0.01780085,  0.00295972],\n",
    "        [-0.094222  ,  0.05571611, -0.04469165,  -0.13713397,\n",
    "          0.02163608, -0.00989413]]])]\n",
    "\n",
    "z = numpy.concatenate(x, y)\n",
    "\n",
    "for i in z:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world how are you today My name is John Doe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = [\"hello\", \"world\", \"how\", \"are\", \"you\", \"today\", \"My\", \"name\", \"is\", \"John\", \"Doe\"]\n",
    "\n",
    "def test_function(docs):\n",
    "    return \" \".join(doc for doc in docs)\n",
    "\n",
    "test_function(retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('human', 'Hi!'), ('ai', 'How can I assist you today?')]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "x = {'context_str': ['hello', 'world', 'how', 'are', 'you', 'today', 'My', 'name', 'is', 'John', 'Doe'], 'question_str': 'What weather are you looking for?', 'system_str': \"System: You are an assistant robot the masterest about weather and climate field in the world. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\", 'type_str': 'text', 'info_str': '', 'variable_name': 'User', 'chat_history': [('human', 'Hi!'), ('ai', 'How can I assist you today?')]}\n",
    "y = itemgetter(\"chat_history\")\n",
    "print(y(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hung\\n Ung\\n Trung\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {\"a\": \"Hung\",\n",
    "     \"b\": \"Ung\",\n",
    "     \"c\": \"Trung\",\n",
    "     }\n",
    "\n",
    "def concat_function(docs):\n",
    "    return \" \".join(str(key + \"\\n\")  for doc, key in docs.items())\n",
    "\n",
    "concat_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import Runnable\n",
    "\n",
    "\n",
    "\n",
    "class StringFormatterRunnable(Runnable):\n",
    "    def __init__(self, prefix=\"Result: \"):\n",
    "        self.prefix = prefix\n",
    "    \n",
    "    def invoke(self, input_data):\n",
    "        # Process input data and format it as a string\n",
    "        result = self.prefix + str(input_data)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Result: Hello world'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = \"Hello world\"\n",
    "retriever_format = StringFormatterRunnable()\n",
    "x = retriever_format.invoke(retriever)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_compressor=CohereRerank(client=<cohere.client.Client object at 0x0000020B4F7BF790>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), user_agent='langchain:partner') base_retriever=<__main__.StringFormatterRunnable object at 0x0000020B51215730>\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, \n",
    "    base_retriever=retriever_format\n",
    ")\n",
    "print(compression_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-cohere in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: cohere<6.0,>=5.5.6 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-cohere) (5.9.4)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-cohere) (0.3.6)\n",
      "Requirement already satisfied: langchain-experimental>=0.3.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-cohere) (0.3.0)\n",
      "Requirement already satisfied: pandas>=1.4.3 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-cohere) (2.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=2 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-cohere) (2.8.2)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-cohere) (0.9.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.35.24)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.9.7)\n",
      "Requirement already satisfied: httpx>=0.21.2 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.27.2)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.4.0)\n",
      "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.9.0)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.20.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.19.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.31.0.6)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (0.1.125)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-cohere) (8.5.0)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-experimental>=0.3.0->langchain-cohere) (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from pandas>=1.4.3->langchain-cohere) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from pandas>=1.4.3->langchain-cohere) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from pydantic<3,>=2->langchain-cohere) (0.7.0)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.24 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.35.24)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (0.10.2)\n",
      "Requirement already satisfied: anyio in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (4.4.0)\n",
      "Requirement already satisfied: certifi in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.5)\n",
      "Requirement already satisfied: idna in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7)\n",
      "Requirement already satisfied: sniffio in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-cohere) (3.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.3.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.5.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-cohere) (3.10.7)\n",
      "Requirement already satisfied: six>=1.5 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.26.20)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.24.6)\n",
      "Requirement already satisfied: types-urllib3 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from types-requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.26.25.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.9.0)\n",
      "Requirement already satisfied: filelock in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2024.6.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (4.66.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (0.3.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (3.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\datascience_for_myself\\projects_myself\\ragmlops\\trimodalrag_system\\rag_env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain-cohere) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCohere\u001b[0m\n",
      "Params: {'temperature': 0.0, 'max_tokens': 128}\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.llms.cohere import Cohere\n",
    "from langchain_cohere.llms import Cohere\n",
    "\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "llms = Cohere(temperature=0.0, \n",
    "            verbose=True,\n",
    "            cohere_api_key= \"\",\n",
    "            max_tokens = 128,\n",
    "            )\n",
    "print(llms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'context_str', 'query'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000020B511AA940>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context_str'], input_types={}, partial_variables={}, template=\"System: You are a helpful assistant that helps you answer questions related to images and videos.----------------------\\n1. Determine the weather forecast: Decide on the weather that you were extracted from the context of the previous question and retriever data.\\n2. Describe the basic weather features in contexts that are relevant: example 'Lightning and lightning accompanied by a heavy wind and drizzle', 'Thick snow covered houses and white roads throughout the area',...\\n3. Provide some effective solution: The best way to avoid them and save more positively when the weather becomes more serious \\n---------------------\\nContext: {context_str}\\n---------------------\\n\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='Metadata: {query}\\n---------------------\\n'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Answer[Bot]: '), additional_kwargs={})])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "template =[\n",
    "    (   \"system\",\n",
    "        (\n",
    "             \"System: You are a helpful assistant that helps you answer questions related to images and videos.\"\n",
    "\n",
    "             \"----------------------\\n\"\n",
    "\n",
    "             \"1. Determine the weather forecast: Decide on the weather that you were extracted from the context of the previous question and retriever data.\\n\"\n",
    "\n",
    "             \"2. Describe the basic weather features in contexts that are relevant: example 'Lightning and lightning accompanied by a heavy wind and drizzle', 'Thick snow covered houses and white roads throughout the area',...\\n\"\n",
    "\n",
    "             \"3. Provide some effective solution: The best way to avoid them and save more positively when the weather becomes more serious \\n\"\n",
    "\n",
    "             \"---------------------\\n\"\n",
    "            \n",
    "            \"Context: {context_str}\\n\"\n",
    "\n",
    "            \"---------------------\\n\"\n",
    "        )\n",
    "    ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "\n",
    "    (\n",
    "        \"user\", \n",
    "        (\n",
    "            \"Metadata: {query}\\n\"\n",
    "            \n",
    "            \"---------------------\\n\"\n",
    "        )\n",
    "    ),\n",
    "        (\n",
    "            \"assistant\", \n",
    "            \"Answer[Bot]: \"\n",
    "        )\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages=template)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=False combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=Cohere(client=<cohere.client.Client object at 0x0000020B59D987F0>, async_client=<cohere.client.AsyncClient object at 0x0000020B511D6040>, temperature=0.0, cohere_api_key=SecretStr('**********'), max_tokens=128), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context') retriever=ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client.Client object at 0x0000020B4F7BF790>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), user_agent='langchain:partner'), base_retriever=<__main__.StringFormatterRunnable object at 0x0000020B51215730>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context_str: RunnablePassthrough(),\n",
       "  query: RunnablePassthrough(),\n",
       "  chat_history: RunnableLambda(itemgetter('chat_history'))\n",
       "}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context_str: RunnablePassthrough(),\n",
       "  query: RunnablePassthrough(),\n",
       "  chat_history: RunnableLambda(itemgetter('chat_history'))\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['chat_history', 'context_str', 'query'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000020B511AA940>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context_str'], input_types={}, partial_variables={}, template=\"System: You are a helpful assistant that helps you answer questions related to images and videos.----------------------\\n1. Determine the weather forecast: Decide on the weather that you were extracted from the context of the previous question and retriever data.\\n2. Describe the basic weather features in contexts that are relevant: example 'Lightning and lightning accompanied by a heavy wind and drizzle', 'Thick snow covered houses and white roads throughout the area',...\\n3. Provide some effective solution: The best way to avoid them and save more positively when the weather becomes more serious \\n---------------------\\nContext: {context_str}\\n---------------------\\n\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='Metadata: {query}\\n---------------------\\n'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Answer[Bot]: '), additional_kwargs={})])\n",
       "| Cohere(client=<cohere.client.Client object at 0x0000020B59D987F0>, async_client=<cohere.client.AsyncClient object at 0x0000020B511D6040>, temperature=0.0, cohere_api_key=SecretStr('**********'), max_tokens=128)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import Runnable, RunnableParallel\n",
    "from operator import itemgetter\n",
    "y = RunnableParallel(\n",
    "    {\n",
    "        \"context_str\": RunnablePassthrough(itemgetter(\"context_str\")), \n",
    "        \"query\": RunnablePassthrough(itemgetter(\"query\")), \n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "    }\n",
    ")\n",
    "chain_new = y | prompt | llms\n",
    "chain_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI model, I do not have access to real-time weather data. Instead, I work with the provided information and the context to answer your query. Since you asked about the weather in London, I can only assume that the context requires me to provide a general overview of the weather. Unfortunately, I do not have any information on the current weather in London. \\n\\nIf you provide more details about the type of weather you want me to describe or any specific weather conditions you're interested in, I'll be happy to provide a response tailored to your requirements. Simply provide the information you want me to work with and I'll\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "\n",
    "chat_history: BaseMessage  = [\n",
    "    HumanMessage(content=\"Hello, How about you with a weather, today?\"),\n",
    "    AIMessage(content=\"Hi, I'm doing well, but more colder for the previous day. How about you?\"),\n",
    "]\n",
    "\n",
    "input_promt = {\"context_str\": x,\"query\": \"What is the weather like in the city of London?\",}\n",
    "metadata = {\n",
    "    **input_promt,\n",
    "    \"chat_history\": chat_history,\n",
    "}\n",
    "\n",
    "chain_new.invoke(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello, How about you with a weather, today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hi, I'm doing well, but more colder for the previous day. How about you?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='1 + 1', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='2', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='3 * 3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='9', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "chat_history: List[BaseMessage]  = [\n",
    "    HumanMessage(content=\"Hello, How about you with a weather, today?\"),\n",
    "    AIMessage(content=\"Hi, I'm doing well, but more colder for the previous day. How about you?\"),\n",
    "]\n",
    "\n",
    "input_promt = {\"query\": \"1 + 1\",\n",
    "               \"answer_text\": \"2\",\n",
    "               \"image\": \"3 * 3\",\n",
    "               \"answer_image\": \"9\"}\n",
    "\n",
    "def format_history(chat_history, input) -> List[BaseMessage]:\n",
    "    for key, text in input.items():\n",
    "        key_str = key.split(\"_\")[0]\n",
    "        \n",
    "        if key_str == \"answer\":\n",
    "            chat_history.append(AIMessage(content=str(text)))\n",
    "        else:\n",
    "            chat_history.append(HumanMessage(content=str(text)))\n",
    "    return chat_history\n",
    "\n",
    "chat_history = format_history(chat_history, input_promt)\n",
    "        \n",
    "chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'query : 1 + 1\\n answer_text : 2\\n image : 3 * 3\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_promt = {\"query\": \"1 + 1\",\n",
    "               \"answer_text\": \"2\",\n",
    "               \"image\": \"3 * 3\",\n",
    "               \"answer_image\": None}\n",
    "\n",
    "def concat_function(docs):\n",
    "    return \" \".join(str(doc) + \" : \" + str(key + \"\\n\")  for doc, key in docs.items() if key != None)\n",
    "\n",
    "ab = concat_function(input_promt)\n",
    "str(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
